{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StudentAdmissions.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "LRkniIFlcziS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Predicting Student Admissions with Neural Networks\n",
        "In this notebook, we predict student admissions to graduate school at UCLA based on three pieces of data:\n",
        "- GRE Scores (Test)\n",
        "- GPA Scores (Grades)\n",
        "- Class rank (1-4)\n",
        "\n",
        "The dataset originally came from here: http://www.ats.ucla.edu/\n",
        "\n",
        "## Loading the data\n",
        "To load the data and format it nicely, we will use two very useful packages called Pandas and Numpy. You can read on the documentation here:\n",
        "- https://pandas.pydata.org/pandas-docs/stable/\n",
        "- https://docs.scipy.org/"
      ]
    },
    {
      "metadata": {
        "id": "pW3r58XhcziY",
        "colab_type": "code",
        "outputId": "735bbd63-e714-4617-db85-4ae9b71da013",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "cell_type": "code",
      "source": [
        "# Importing pandas and numpy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data_link = 'https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/intro-neural-networks/student-admissions/student_data.csv'\n",
        "# Reading the csv file into a pandas DataFrame\n",
        "data = pd.read_csv(data_link)\n",
        "\n",
        "# Printing out the first 10 rows of our data\n",
        "data[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>admit</th>\n",
              "      <th>gre</th>\n",
              "      <th>gpa</th>\n",
              "      <th>rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>380</td>\n",
              "      <td>3.61</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>660</td>\n",
              "      <td>3.67</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>800</td>\n",
              "      <td>4.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>640</td>\n",
              "      <td>3.19</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>520</td>\n",
              "      <td>2.93</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>760</td>\n",
              "      <td>3.00</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>560</td>\n",
              "      <td>2.98</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>400</td>\n",
              "      <td>3.08</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>540</td>\n",
              "      <td>3.39</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>700</td>\n",
              "      <td>3.92</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   admit  gre   gpa  rank\n",
              "0      0  380  3.61     3\n",
              "1      1  660  3.67     3\n",
              "2      1  800  4.00     1\n",
              "3      1  640  3.19     4\n",
              "4      0  520  2.93     4\n",
              "5      1  760  3.00     2\n",
              "6      1  560  2.98     1\n",
              "7      0  400  3.08     2\n",
              "8      1  540  3.39     3\n",
              "9      0  700  3.92     2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "8N92EoFJczig",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Plotting the data\n",
        "\n",
        "First let's make a plot of our data to see how it looks. In order to have a 2D plot, let's ingore the rank."
      ]
    },
    {
      "metadata": {
        "id": "op5mEu79czii",
        "colab_type": "code",
        "outputId": "b10d4bfc-3731-4425-bb49-23062f327246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "cell_type": "code",
      "source": [
        "# Importing matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Function to help us plot\n",
        "def plot_points(data):\n",
        "    X = np.array(data[[\"gre\",\"gpa\"]])\n",
        "    y = np.array(data[\"admit\"])\n",
        "    admitted = X[np.argwhere(y==1)]\n",
        "    rejected = X[np.argwhere(y==0)]\n",
        "    plt.scatter([s[0][0] for s in rejected], [s[0][1] for s in rejected], s = 25, color = 'red', edgecolor = 'k')\n",
        "    plt.scatter([s[0][0] for s in admitted], [s[0][1] for s in admitted], s = 25, color = 'cyan', edgecolor = 'k')\n",
        "    plt.xlabel('Test (GRE)')\n",
        "    plt.ylabel('Grades (GPA)')\n",
        "    \n",
        "# Plotting the points\n",
        "plot_points(data)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npZTaPgB2wxK0/0j9GgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f6165cda518>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "dghEaNOaczin",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Roughly, it looks like the students with high scores in the grades and test passed, while the ones with low scores didn't, but the data is not as nicely separable as we hoped it would. Maybe it would help to take the rank into account? Let's make 4 plots, each one for each rank."
      ]
    },
    {
      "metadata": {
        "id": "fNgAKjWsczip",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Separating the ranks\n",
        "data_rank1 = data[data[\"rank\"]==1]\n",
        "data_rank2 = data[data[\"rank\"]==2]\n",
        "data_rank3 = data[data[\"rank\"]==3]\n",
        "data_rank4 = data[data[\"rank\"]==4]\n",
        "\n",
        "# Plotting the graphs\n",
        "plot_points(data_rank1)\n",
        "plt.title(\"Rank 1\")\n",
        "plt.show()\n",
        "plot_points(data_rank2)\n",
        "plt.title(\"Rank 2\")\n",
        "plt.show()\n",
        "plot_points(data_rank3)\n",
        "plt.title(\"Rank 3\")\n",
        "plt.show()\n",
        "plot_points(data_rank4)\n",
        "plt.title(\"Rank 4\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-T3phGyCcziu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This looks more promising, as it seems that the lower the rank, the higher the acceptance rate. Let's use the rank as one of our inputs. In order to do this, we should one-hot encode it.\n",
        "\n",
        "## TODO: One-hot encoding the rank\n",
        "Use the `get_dummies` function in pandas in order to one-hot encode the data.\n",
        "\n",
        "Hint: To drop a column, it's suggested that you use `one_hot_data`[.drop( )](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html)."
      ]
    },
    {
      "metadata": {
        "id": "uXUL-fE9cziw",
        "colab_type": "code",
        "outputId": "14f7c259-b769-4e76-dbdf-015c03f10f2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "# TODO:  Make dummy variables for rank\n",
        "one_hot_data =  pd.concat([data.drop('rank',axis=1), pd.get_dummies(data['rank'], prefix='Rank_')], axis=1)\n",
        "\n",
        "# TODO: Drop the previous rank column\n",
        "one_hot_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>admit</th>\n",
              "      <th>gre</th>\n",
              "      <th>gpa</th>\n",
              "      <th>Rank__1</th>\n",
              "      <th>Rank__2</th>\n",
              "      <th>Rank__3</th>\n",
              "      <th>Rank__4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>380</td>\n",
              "      <td>3.61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>660</td>\n",
              "      <td>3.67</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>800</td>\n",
              "      <td>4.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>640</td>\n",
              "      <td>3.19</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>520</td>\n",
              "      <td>2.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   admit  gre   gpa  Rank__1  Rank__2  Rank__3  Rank__4\n",
              "0      0  380  3.61        0        0        1        0\n",
              "1      1  660  3.67        0        0        1        0\n",
              "2      1  800  4.00        1        0        0        0\n",
              "3      1  640  3.19        0        0        0        1\n",
              "4      0  520  2.93        0        0        0        1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "xa7uo8Yoczi1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## TODO: Scaling the data\n",
        "The next step is to scale the data. We notice that the range for grades is 1.0-4.0, whereas the range for test scores is roughly 200-800, which is much larger. This means our data is skewed, and that makes it hard for a neural network to handle. Let's fit our two features into a range of 0-1, by dividing the grades by 4.0, and the test score by 800."
      ]
    },
    {
      "metadata": {
        "id": "Ye72D6FUczi2",
        "colab_type": "code",
        "outputId": "efa77acd-09bf-43c6-98b6-df44a9b8a008",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "cell_type": "code",
      "source": [
        "# Making a copy of our data\n",
        "processed_data = one_hot_data[:]\n",
        "\n",
        "# TODO: Scale the columns\n",
        "processed_data['gre'] = processed_data['gre']/800\n",
        "processed_data['gpa'] = processed_data['gpa']/4\n",
        "\n",
        "# Printing the first 10 rows of our procesed data\n",
        "processed_data[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>admit</th>\n",
              "      <th>gre</th>\n",
              "      <th>gpa</th>\n",
              "      <th>Rank__1</th>\n",
              "      <th>Rank__2</th>\n",
              "      <th>Rank__3</th>\n",
              "      <th>Rank__4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.475</td>\n",
              "      <td>0.9025</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.825</td>\n",
              "      <td>0.9175</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.800</td>\n",
              "      <td>0.7975</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.650</td>\n",
              "      <td>0.7325</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>0.950</td>\n",
              "      <td>0.7500</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.7450</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.7700</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>0.675</td>\n",
              "      <td>0.8475</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.9800</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   admit    gre     gpa  Rank__1  Rank__2  Rank__3  Rank__4\n",
              "0      0  0.475  0.9025        0        0        1        0\n",
              "1      1  0.825  0.9175        0        0        1        0\n",
              "2      1  1.000  1.0000        1        0        0        0\n",
              "3      1  0.800  0.7975        0        0        0        1\n",
              "4      0  0.650  0.7325        0        0        0        1\n",
              "5      1  0.950  0.7500        0        1        0        0\n",
              "6      1  0.700  0.7450        1        0        0        0\n",
              "7      0  0.500  0.7700        0        1        0        0\n",
              "8      1  0.675  0.8475        0        0        1        0\n",
              "9      0  0.875  0.9800        0        1        0        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "3kXp_ww0czjA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Splitting the data into Training and Testing"
      ]
    },
    {
      "metadata": {
        "id": "wVygOclcczjB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In order to test our algorithm, we'll split the data into a Training and a Testing set. The size of the testing set will be 10% of the total data."
      ]
    },
    {
      "metadata": {
        "id": "YZd9G-SRczjD",
        "colab_type": "code",
        "outputId": "ad0258c3-1c23-492a-9d42-39de1b91d0fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "cell_type": "code",
      "source": [
        "sample = np.random.choice(processed_data.index, size=int(len(processed_data)*0.9), replace=False)\n",
        "train_data, test_data = processed_data.iloc[sample], processed_data.drop(sample)\n",
        "\n",
        "print(\"Number of training samples is\", len(train_data))\n",
        "print(\"Number of testing samples is\", len(test_data))\n",
        "print(train_data[:10])\n",
        "print(test_data[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training samples is 360\n",
            "Number of testing samples is 40\n",
            "     admit    gre     gpa  Rank__1  Rank__2  Rank__3  Rank__4\n",
            "297      0  0.575  0.7675        0        1        0        0\n",
            "57       0  0.475  0.7350        0        0        1        0\n",
            "232      0  0.475  0.8450        0        1        0        0\n",
            "264      1  0.650  0.9750        0        0        1        0\n",
            "67       0  0.775  0.8250        1        0        0        0\n",
            "147      0  0.700  0.6775        0        0        1        0\n",
            "184      0  0.625  0.6975        0        0        0        1\n",
            "180      0  0.775  0.9450        0        0        1        0\n",
            "20       0  0.625  0.7925        0        0        1        0\n",
            "69       0  1.000  0.9325        1        0        0        0\n",
            "    admit    gre     gpa  Rank__1  Rank__2  Rank__3  Rank__4\n",
            "19      1  0.675  0.9525        1        0        0        0\n",
            "21      1  0.825  0.9075        0        1        0        0\n",
            "22      0  0.750  0.7050        0        0        0        1\n",
            "31      0  0.950  0.8375        0        0        1        0\n",
            "45      1  0.575  0.8625        0        0        1        0\n",
            "47      0  0.625  0.7425        0        0        0        1\n",
            "50      0  0.800  0.9650        0        0        1        0\n",
            "51      0  0.550  0.7825        0        0        0        1\n",
            "83      0  0.475  0.7275        0        0        0        1\n",
            "99      0  0.500  0.8275        0        0        1        0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vxz2DR9XczjJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Splitting the data into features and targets (labels)\n",
        "Now, as a final step before the training, we'll split the data into features (X) and targets (y)."
      ]
    },
    {
      "metadata": {
        "id": "3gm3E3LHczjK",
        "colab_type": "code",
        "outputId": "a45d8ce8-6724-4c6b-9c62-96ddb6fc9e92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "features = train_data.drop('admit', axis=1)\n",
        "targets = train_data['admit']\n",
        "features_test = test_data.drop('admit', axis=1)\n",
        "targets_test = test_data['admit']\n",
        "\n",
        "print(features[:10])\n",
        "print(targets[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       gre     gpa  Rank__1  Rank__2  Rank__3  Rank__4\n",
            "297  0.575  0.7675        0        1        0        0\n",
            "57   0.475  0.7350        0        0        1        0\n",
            "232  0.475  0.8450        0        1        0        0\n",
            "264  0.650  0.9750        0        0        1        0\n",
            "67   0.775  0.8250        1        0        0        0\n",
            "147  0.700  0.6775        0        0        1        0\n",
            "184  0.625  0.6975        0        0        0        1\n",
            "180  0.775  0.9450        0        0        1        0\n",
            "20   0.625  0.7925        0        0        1        0\n",
            "69   1.000  0.9325        1        0        0        0\n",
            "297    0\n",
            "57     0\n",
            "232    0\n",
            "264    1\n",
            "67     0\n",
            "147    0\n",
            "184    0\n",
            "180    0\n",
            "20     0\n",
            "69     0\n",
            "Name: admit, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sTyOgB90czjP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training the 2-layer Neural Network\n",
        "The following function trains the 2-layer neural network. First, we'll write some helper functions."
      ]
    },
    {
      "metadata": {
        "id": "P0OcqrYcczjR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Activation (sigmoid) function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "def sigmoid_prime(x):\n",
        "    return sigmoid(x) * (1-sigmoid(x))\n",
        "def error_formula(y, output):\n",
        "    return - y*np.log(output) - (1 - y) * np.log(1-output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kKDDgxiUczjW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TODO: Backpropagate the error\n",
        "Now it's your turn to shine. Write the error term. Remember that this is given by the equation $$ (y-\\hat{y}) \\sigma'(x) $$"
      ]
    },
    {
      "metadata": {
        "id": "R6umlJXGczjY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: Write the error term formula\n",
        "def error_term_formula(x, y, output):\n",
        "    return (y - output)*sigmoid_prime(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9XXrKgYFczjc",
        "colab_type": "code",
        "outputId": "a9cc6add-d822-4f60-cec8-cb6f24dd0caf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "cell_type": "code",
      "source": [
        "# Neural Network hyperparameters\n",
        "epochs = 10000\n",
        "learnrate = 0.01\n",
        "\n",
        "# Training function\n",
        "def train_nn(features, targets, epochs, learnrate):\n",
        "    \n",
        "    # Use to same seed to make debugging easier\n",
        "    np.random.seed(42)\n",
        "\n",
        "    n_records, n_features = features.shape\n",
        "    last_loss = None\n",
        "\n",
        "    # Initialize weights\n",
        "    weights = np.random.normal(scale=1 / n_features**.5, size=n_features)\n",
        "\n",
        "    for e in range(epochs):\n",
        "        del_w = np.zeros(weights.shape)\n",
        "        for x, y in zip(features.values, targets):\n",
        "            # Loop through all records, x is the input, y is the target\n",
        "\n",
        "            # Activation of the output unit\n",
        "            #   Notice we multiply the inputs and the weights here \n",
        "            #   rather than storing h as a separate variable \n",
        "            output = sigmoid(np.dot(x, weights))\n",
        "\n",
        "            # The error, the target minus the network output\n",
        "            error = error_formula(y, output)\n",
        "\n",
        "            # The error term\n",
        "            error_term = error_term_formula(x, y, output)\n",
        "\n",
        "            # The gradient descent step, the error times the gradient times the inputs\n",
        "            del_w += error_term * x\n",
        "\n",
        "        # Update the weights here. The learning rate times the \n",
        "        # change in weights, divided by the number of records to average\n",
        "        weights += learnrate * del_w / n_records\n",
        "\n",
        "        # Printing out the mean square error on the training set\n",
        "        if e % (epochs / 10) == 0:\n",
        "            out = sigmoid(np.dot(features, weights))\n",
        "            loss = np.mean((out - targets) ** 2)\n",
        "            print(\"Epoch:\", e)\n",
        "            if last_loss and last_loss < loss:\n",
        "                print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
        "            else:\n",
        "                print(\"Train loss: \", loss)\n",
        "            last_loss = loss\n",
        "            print(\"=========\")\n",
        "    print(\"Finished training!\")\n",
        "    return weights\n",
        "    \n",
        "weights = train_nn(features, targets, epochs, learnrate)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Train loss:  0.2814649282734821\n",
            "=========\n",
            "Epoch: 1000\n",
            "Train loss:  0.22265971644084404\n",
            "=========\n",
            "Epoch: 2000\n",
            "Train loss:  0.21003691292911353\n",
            "=========\n",
            "Epoch: 3000\n",
            "Train loss:  0.2066677827211635\n",
            "=========\n",
            "Epoch: 4000\n",
            "Train loss:  0.20524648682200733\n",
            "=========\n",
            "Epoch: 5000\n",
            "Train loss:  0.204316784480621\n",
            "=========\n",
            "Epoch: 6000\n",
            "Train loss:  0.20356399787285107\n",
            "=========\n",
            "Epoch: 7000\n",
            "Train loss:  0.2029137486586289\n",
            "=========\n",
            "Epoch: 8000\n",
            "Train loss:  0.20234394543549036\n",
            "=========\n",
            "Epoch: 9000\n",
            "Train loss:  0.20184374923679615\n",
            "=========\n",
            "Finished training!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3-dt0tM-czjh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Calculating the Accuracy on the Test Data"
      ]
    },
    {
      "metadata": {
        "id": "hmj1lyMhczji",
        "colab_type": "code",
        "outputId": "4290c82b-2f81-40a1-a52b-755464af4bc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Calculate accuracy on test data\n",
        "test_out = sigmoid(np.dot(features_test, weights))\n",
        "predictions = test_out > 0.5\n",
        "accuracy = np.mean(predictions == targets_test)\n",
        "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction accuracy: 0.575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FPD17A6xhXP8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}